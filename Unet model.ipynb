{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doubleConv(in_channels, out_channels, kernels=3, pad=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size=kernels, padding=pad),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(out_channels, out_channels, kernel_size=kernels, padding=pad),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_channels, n_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.downConv1 = doubleConv(input_channels, 64)\n",
    "        self.downConv2 = doubleConv(64, 128)\n",
    "        self.downConv3 = doubleConv(128, 256)\n",
    "        self.downConv4 = doubleConv(256, 512)\n",
    "        \n",
    "        self.maxPoolLayer = nn.MaxPool2d(2) # kernel size will reduce both dimension by half\n",
    "        self.upsampleLayer = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        \n",
    "        self.upConv3 = doubleConv(256+512, 256)\n",
    "        self.upConv2 = doubleConv(128+256, 128)\n",
    "        self.upConv1 = doubleConv(64+128, 64)\n",
    "        \n",
    "        self.finalConv = doubleConv(64, n_classes, kernels=1, pad=0) # final 1x1 kernel conv layer with depth=n_classes\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        conv_r1 = self.downConv1(x)      #Conv Layer 1,2\n",
    "        x = self.maxPoolLayer(conv_r1)   #Pool Layer 3\n",
    "        \n",
    "        conv_r2 = self.downConv2(x)      #Conv Layer 4,5\n",
    "        x = self.maxPoolLayer(conv_r2)   #Pool Layer 6\n",
    "        \n",
    "        conv_r3 = self.downConv3(x)      #Conv Layer 7,8\n",
    "        x = self.maxPoolLayer(conv_r3)   #Conv Layer 9\n",
    "        \n",
    "        x = self.downConv4(x)            #Conv Layer 10,11\n",
    "        \n",
    "        x = self.upsampleLayer(x)        #Upsampling Layer 12\n",
    "        \n",
    "        x = torch.cat([conv_r3, x], dim=1) # concatenate\n",
    "        x = self.upConv3(x)              # Conv Layer 13,14\n",
    "        \n",
    "        x = self.upsampleLayer(x)        # Upsampling Layer 15\n",
    "        \n",
    "        x = torch.cat([conv_r2, x], dim=1) \n",
    "        x = self.upConv2(x)              # Conv Layer 16,17\n",
    "        \n",
    "        x = self.upsampleLayer(x)        # Upsampling Layer 18\n",
    "        \n",
    "        x = torch.cat([conv_r1, x], dim=1) \n",
    "        x = self.upConv1(x)              # Conv Layer 19,20\n",
    "        \n",
    "        out = self.finalConv(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CityscapesUnet(nn.Module): #Wrapper Unet class for dataset classes & softmax\n",
    "    \n",
    "    def __init__(self, input_channels):\n",
    "        super.__init__()\n",
    "        \n",
    "        n_classes=34          #Fixed for cityscapes dataset\n",
    "        self.Unet = UNet(input_channels, 34)\n",
    "        self.softmaxLayer = nn.Softmax(dim=1)  # softmax on depth of tensor\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \n",
    "        X = self.softmaxLayer(self.Unet(X))\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 128, 256])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor = torch.randn((1, 3, 128, 256))\n",
    "test_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input channels, num_classes\n",
    "learner = UNet(3, 34)\n",
    "# learner = learner.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x0000016A50736148>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 34, 128, 256])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "op = learner(test_tensor)\n",
    "op.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[  4.2098,   9.6302,   4.9260,  11.6340],\n",
       "          [ -5.3136,  13.0683,  -7.0615,  -9.5064],\n",
       "          [  4.6390,   9.8135,   2.2820,  -5.2707],\n",
       "          [ -5.9274,  -2.8761,   1.1233,  -1.4763]],\n",
       "\n",
       "         [[  9.5644,  10.8344,  -2.6058,  14.3671],\n",
       "          [-11.2367,  -3.7074,   2.1452,   4.0693],\n",
       "          [-11.9275,  32.0497,   2.4363,  12.6367],\n",
       "          [ -7.2436,   5.8231, -15.9325,   6.6507]],\n",
       "\n",
       "         [[ -5.8009,  -0.8185,  -3.3179,   6.3987],\n",
       "          [  7.2884,  -0.1063,   9.9496,  11.0945],\n",
       "          [ -7.6305,   4.9629, -10.1745, -10.4062],\n",
       "          [  4.2417,  -4.9165,   0.9865,  -0.9399]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_tensor2 = torch.randn((1, 3, 4, 4))*1087\n",
    "test_tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[4.7041e-03, 2.3073e-01, 9.9920e-01, 6.1031e-02],\n",
       "          [3.3650e-06, 1.0000e+00, 4.0925e-08, 1.1291e-09],\n",
       "          [1.0000e+00, 2.2026e-10, 4.6150e-01, 1.6708e-08],\n",
       "          [3.8335e-05, 1.6669e-04, 5.3415e-01, 2.9521e-04]],\n",
       "\n",
       "         [[9.9530e-01, 7.6926e-01, 5.3532e-04, 9.3864e-01],\n",
       "          [9.0084e-09, 5.1807e-08, 4.0779e-04, 8.8841e-04],\n",
       "          [6.3860e-08, 1.0000e+00, 5.3850e-01, 1.0000e+00],\n",
       "          [1.0280e-05, 9.9981e-01, 2.0913e-08, 9.9920e-01]],\n",
       "\n",
       "         [[2.1128e-07, 6.6878e-06, 2.6266e-04, 3.2500e-04],\n",
       "          [1.0000e+00, 1.8981e-06, 9.9959e-01, 9.9911e-01],\n",
       "          [4.6925e-06, 1.7231e-12, 1.7964e-06, 9.8306e-11],\n",
       "          [9.9995e-01, 2.1665e-05, 4.6585e-01, 5.0476e-04]]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.Softmax(dim=1)\n",
    "op = m(test_tensor2)\n",
    "op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 0, 1],\n",
       "         [2, 0, 2, 2],\n",
       "         [0, 1, 1, 1],\n",
       "         [2, 1, 0, 1]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, op_idx = torch.max(op, dim=1)\n",
    "op_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
